"""API endpoints for the Agent-to-Agent (A2A) protocol.

This module defines the FastAPI router for handling A2A messages,
task management, and agent capabilities discovery.
"""

import os
import logging
from typing import Dict
from fastapi import APIRouter, HTTPException, BackgroundTasks, Request

from a2a.models import (
    SendMessageRequest, Task, TaskStatus, TaskState, Message, Role, Part, FilePart,
    AgentCard, MessageType, ModificationData, BuildabilityMetadata, ModelMetadata,
    GenerateOptions, ModelSizeEnum
)
from a2a.task_manager import TaskManager
from runner import run_agent, run_modification_agent, control_flow_agent
from config import settings
from tools.cad_tools import task_id_var
from models.generation_options import MODEL_SIZE_SPECS, ModelSize

logger = logging.getLogger(__name__)

router = APIRouter()
task_manager = TaskManager()

def _find_generated_files(task_id: str, output_dir: str) -> list[Part]:
    """Scans the output directory for files generated by the task.

    Args:
        task_id (str): The task identifier.
        output_dir (str): The directory to scan.

    Returns:
        list[Part]: A list of file parts found.
    """
    parts = []
    if not os.path.exists(output_dir):
        return parts

    for filename in os.listdir(output_dir):
        if not filename.startswith(task_id):
            continue
            
        if filename.endswith(".stl"):
            parts.append(Part(file=FilePart(
                file_with_uri=f"/download/{filename}",
                name=filename,
                media_type="model/stl"
            )))
        elif filename.endswith(".step"):
            parts.append(Part(file=FilePart(
                file_with_uri=f"/download/{filename}",
                name=filename,
                media_type="model/step"
            )))
    return parts

async def process_a2a_task(
    task_id: str,
    prompt: str,
    context_id: str,
    generation_options: GenerateOptions | None = None
) -> None:
    """Process an A2A generation task in the background.

    Args:
        task_id (str): The unique identifier for the task.
        prompt (str): The input prompt from the user/agent.
        context_id (str): The context or session ID.
        generation_options (GenerateOptions | None): Optional generation options (model size, etc.)
    """
    logger.info(f"Processing A2A generation task {task_id} with prompt: {prompt}")
    if generation_options:
        logger.info(f"Generation options: model_size={generation_options.model_size}, "
                   f"complexity={generation_options.complexity}")

    task_manager.update_task_status(task_id, TaskState.WORKING)

    # Set the task ID in the context variable so tools can use it
    token = task_id_var.set(task_id)

    try:
        final_response = ""

        # Add model size info to prompt if specified
        enhanced_prompt = prompt
        if generation_options and generation_options.model_size:
            size = generation_options.model_size
            if size != ModelSizeEnum.CUSTOM:
                # Map A2A enum to internal enum
                internal_size = ModelSize(size.value)
                spec = MODEL_SIZE_SPECS.get(internal_size, MODEL_SIZE_SPECS[ModelSize.SMALL])
                enhanced_prompt = f"""[MODEL SIZE: {spec.get('display_name', size.value).upper()}]
Target brick count: {spec['min_bricks']}-{spec['max_bricks']} bricks
Target layer count: {spec['min_layers']}-{spec['max_layers']} layers

{prompt}"""
            elif generation_options.custom_settings:
                cs = generation_options.custom_settings
                enhanced_prompt = f"""[MODEL SIZE: CUSTOM]
Target brick count: {cs.min_bricks}-{cs.max_bricks} bricks
Target layer count: {cs.min_layers}-{cs.max_layers} layers

{prompt}"""

        # Execute the agent workflow via Runner
        async for response_chunk in run_agent(
            prompt=enhanced_prompt, 
            session_id=context_id,
            generation_options=generation_options
        ):
            final_response = response_chunk

        # Check for generated files in outputs/ matching the task ID
        file_parts = _find_generated_files(task_id, settings.OUTPUT_DIR)

        # Build response parts including buildability metadata
        response_parts = [Part(text=final_response)] + file_parts

        # Get buildability result from control flow agent
        buildability_result = control_flow_agent.get_last_buildability_result()
        buildability_data = None

        if buildability_result:
            buildability_data = BuildabilityMetadata(
                score=buildability_result.score,
                valid=buildability_result.valid,
                layer_count=buildability_result.layer_count,
                issues=buildability_result.issues,
                recommendations=buildability_result.recommendations,
                estimated_build_time_minutes=buildability_result.estimated_build_time_minutes,
                build_sequence=[b.to_dict() for b in buildability_result.build_sequence]
            )

            # Add buildability metadata as a data part
            response_parts.append(Part(
                data={
                    "buildability": buildability_data.model_dump(),
                    "model_metadata": {
                        "brick_count": len(buildability_result.build_sequence),
                        "layer_count": buildability_result.layer_count
                    }
                },
                metadata={"type": "buildability_result"}
            ))

        response_message = Message(
            role=Role.AGENT,
            parts=response_parts
        )

        # Set artifacts on the task so frontend can access STL files
        from a2a.models import Artifact
        if file_parts:
            task = task_manager.get_task(task_id)
            if task:
                task.artifacts = Artifact(parts=file_parts)
                # Also store buildability in task metadata
                if buildability_data:
                    task.metadata = task.metadata or {}
                    task.metadata["buildability"] = buildability_data.model_dump()
                    task.metadata["model_metadata"] = {
                        "brick_count": len(buildability_result.build_sequence) if buildability_result else 0,
                        "layer_count": buildability_result.layer_count if buildability_result else 0
                    }

        task_manager.update_task_status(task_id, TaskState.COMPLETED, response_message)

        logger.info(f"A2A generation task {task_id} completed successfully")
        if buildability_result:
            logger.info(f"Buildability: score={buildability_result.score}, valid={buildability_result.valid}")

    except Exception as e:
        error_msg = f"Internal error during generation: {str(e)}"
        response_message = Message(
            role=Role.AGENT,
            parts=[Part(text=error_msg)]
        )
        task_manager.update_task_status(task_id, TaskState.FAILED, response_message)
        logger.error(f"A2A generation task {task_id} exception: {e}")

    finally:
        # Reset the context variable
        task_id_var.reset(token)


async def process_modification_task(
    task_id: str,
    modification_data: ModificationData,
    context_id: str
) -> None:
    """Process an A2A modification task in the background.

    Args:
        task_id (str): The unique identifier for the task.
        modification_data (ModificationData): The modification request data.
        context_id (str): The context or session ID.
    """
    # Log modification request details (truncate potentially sensitive code)
    logger.info(
        f"Processing A2A modification task {task_id} with prompt: "
        f"{modification_data.modification_prompt[:100]}..."
    )
    logger.info(
        f"Modification task {task_id}: base_model_id={modification_data.base_model_id}, "
        f"base_code_length={len(modification_data.base_code)} chars"
    )

    task_manager.update_task_status(task_id, TaskState.WORKING)

    # Set the task ID in the context variable so tools can use it
    token = task_id_var.set(task_id)

    try:
        final_response = ""
        # Convert inventory to list of dicts if present
        inventory_list = None
        if modification_data.inventory:
            inventory_list = [
                {"size": b.size, "color": b.color, "count": b.count}
                for b in modification_data.inventory
            ]

        # Execute the modification agent workflow via Runner
        async for response_chunk in run_modification_agent(
            existing_code=modification_data.base_code,
            modification_prompt=modification_data.modification_prompt,
            session_id=context_id,
            inventory=inventory_list
        ):
            final_response = response_chunk

        # Check for generated files in outputs/ matching the task ID
        file_parts = _find_generated_files(task_id, settings.OUTPUT_DIR)
        parts = [Part(text=final_response)] + file_parts

        response_message = Message(
            role=Role.AGENT,
            parts=parts
        )

        # Set artifacts on the task so frontend can access STL files
        from a2a.models import Artifact
        if file_parts:
            task = task_manager.get_task(task_id)
            if task:
                task.artifacts = Artifact(parts=file_parts)

        task_manager.update_task_status(task_id, TaskState.COMPLETED, response_message)

        logger.info(f"A2A modification task {task_id} completed successfully")

    except Exception as e:
        error_msg = f"Modification not possible. Try rephrasing or use regenerate. Error: {str(e)}"
        response_message = Message(
            role=Role.AGENT,
            parts=[Part(text=error_msg)]
        )
        task_manager.update_task_status(task_id, TaskState.FAILED, response_message)
        logger.error(f"A2A modification task {task_id} exception: {e}")

    finally:
        # Reset the context variable
        task_id_var.reset(token)

@router.post("/v1/message:send")
async def a2a_send_message(request: SendMessageRequest, background_tasks: BackgroundTasks) -> Dict[str, Task]:
    """Handle incoming A2A messages and start a background task.

    Supports both generation (text_to_lego, image_to_lego) and modification
    (modify_lego_model) message types.

    Args:
        request (SendMessageRequest): The incoming message request.
        background_tasks (BackgroundTasks): FastAPI background tasks handler.

    Returns:
        Dict[str, Task]: A dictionary containing the created task.

    Raises:
        HTTPException: If the message content is empty or modification data is missing.
    """
    # Handle modification requests
    if request.message_type == MessageType.MODIFY_LEGO_MODEL:
        if not request.modification_data:
            raise HTTPException(
                status_code=400,
                detail="modification_data is required for modify_lego_model message type"
            )

        if not request.modification_data.base_code:
            raise HTTPException(
                status_code=400,
                detail="base_code is required for modification requests"
            )

        if not request.modification_data.modification_prompt:
            raise HTTPException(
                status_code=400,
                detail="modification_prompt is required for modification requests"
            )

        # Create Task
        task = task_manager.create_task(context_id=request.message.context_id)

        # Log modification request separately for analytics
        logger.info(
            "Modification request received",
            extra={
                "type": "modify_lego_model",
                "task_id": task.id,
                "base_model_id": request.modification_data.base_model_id,
                "modification_prompt": request.modification_data.modification_prompt[:50],
            }
        )

        # Start background processing for modification
        background_tasks.add_task(
            process_modification_task,
            task.id,
            request.modification_data,
            request.message.context_id
        )

        return {"task": task}

    # Handle generation requests (text_to_lego, image_to_lego)
    # Extract prompt from the first text part
    prompt = ""
    for part in request.message.parts:
        if part.text:
            prompt += part.text + "\n"

    if not prompt.strip():
        raise HTTPException(status_code=400, detail="No text content found in message")

    # Create Task
    task = task_manager.create_task(context_id=request.message.context_id)

    # Log generation request for analytics
    logger.info(
        "Generation request received",
        extra={
            "type": str(request.message_type),
            "task_id": task.id,
            "prompt": prompt[:50],
        }
    )

    # Start background processing with generation options
    background_tasks.add_task(
        process_a2a_task,
        task.id,
        prompt.strip(),
        request.message.context_id,
        request.generation_options
    )

    return {"task": task}

@router.get("/v1/tasks/{id}")
async def a2a_get_task(id: str) -> Dict[str, Task]:
    """Retrieve the status of a specific task.

    Args:
        id (str): The task identifier.

    Returns:
        Dict[str, Task]: A dictionary containing the task details.

    Raises:
        HTTPException: If the task is not found.
    """
    task = task_manager.get_task(id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    return {"task": task}

@router.get("/v1/extendedAgentCard")
async def a2a_get_agent_card(request: Request) -> AgentCard:
    """Provide the extended agent card describing capabilities.

    Args:
        request (Request): The incoming HTTP request.

    Returns:
        AgentCard: The agent card object.
    """
    base_url = str(request.base_url).rstrip("/")
    return AgentCard(
        identity={
            "name": "FormaAI 3D Agent",
            "description": "Generates and modifies 3D LEGO models (STL/STEP) from natural language descriptions using build123d and Gemini 3 Pro.",
            "author": "FormaAI Team",
            "license": "Apache-2.0"
        },
        capabilities={
            "input_types": ["text/plain", "application/json"],
            "output_types": ["model/stl", "model/step", "text/x-python"],
            "models": ["gemini-3-pro-preview"],
            "message_types": ["text_to_lego", "image_to_lego", "modify_lego_model"],
            "supports_modification": True
        },
        supported_interfaces=[
            {
                "transport": "http",
                "url": f"{base_url}/v1/message:send"
            }
        ]
    )

@router.get("/.well-known/agent-card.json")
async def a2a_well_known_card(request: Request) -> AgentCard:
    """Serve the well-known agent card for discovery.

    Args:
        request (Request): The incoming HTTP request.

    Returns:
        AgentCard: The agent card object.
    """
    return await a2a_get_agent_card(request)
